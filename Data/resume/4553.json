{"skills": ["kafka", "scala", "azure blob storage", "cloud service", "streaming data", "series data", "data warehouse", "analysis", "amazon ec2", "tivoli", "visualization", "business analyst", "management tool", "nosql", "pentaho", "testing", "oracle", "cognos", "azure", "management information system", "telecom system", "aws", "olap", "data security", "java", "cassandra", "cloud", "data mining", "banking", "administration", "sql database", "enterprise", "object oriented", "data mart", "etl", "gap analysis", "data analysis", "medium", "maintenance", "google bigquery", "asset management", "rss", "ibm", "hadoop", "bigquery", "information management", "hdfs", "problem solving", "parallelism", "business requirement analysis", "workflow", "analytics", "management", "data warehouse system", "business requirement", "business intelligence", "star schema", "relational database", "data warehouse architecture", "database", "clarify", "problem solving skill", "materialized view", "bi publisher", "analyst", "hue", "automation", "scripting language", "process automation", "ams", "implementation", "database management", "azure stream analytics", "security", "structure", "leadership skill", "synchronization", "azure storage", "sql", "microsoft", "obiee", "python", "streaming", "scripting"], "fulltext": "\uf19d\n EDUCATION\nUNIVERSITY ECONOMIC OF HCM\nAUG 2009 - APR 2013\nMajor: Bachelor of Management Information System\nGPA: 7.6\n\uf0b1\nWORK EXPERIENCE\nJUST ANALYTICS\n04/2018 - PRESENT\nTechnical Consultant\nI\u2019m a consultant for Business Intelligence and Azure data lake storage over 4 years of\nexperience in the Information Technology industry in administering the data of the\norganization professionally. I have demonstrated ability to effectively communicate\nwith local customers and conduct complete project life cycles, from initial planning and\nneeds determination to final testing and deployment of Azure storage as back-end,\nfront-end of which is implemented by using Power BI and Rstudio. I continue to be\ninvolved with every phase of the life cycle development, including business requirement\nanalysis, designing, organizing and maintaining the data collected from diverse sources\nand building the large and medium Data Warehouse and Business Intelligence projects,\nsome are using Oracle BI Apps to implementand HDFS. I also have hands-on\nexperience in designing, developing and implementing in Data pipeline for Data\nstreaming as Azure stream analytics. I\u2019m detail oriented and commited to delivering\nsuperior quality work. I\u2019m seeking a challenging position as a Data Scientists with an\norganization where high responsibility, fast learning, good communication with clients,\neffective problem solving skills, leadership and organizational skills would be needed.\nMSERVICE - MOMO\n2016 - 04/2018\nBusiness intelligence Manager\nAs the part of the best fin-tech company in Vietnam, my responsibility is to aggregate\ndata from many sources to build-up a decision support system to give the warning or\nstrategy decision for board of management. Beside, we also design process to\ntransform data in non-SQL structure of customers (videos, audio, record, image,\nemotion..) to meaningful data that user properties is core support analyzing and answer\nuser's behaviour and their character.\nExperience:\n  -  Big data tools: Hadoop, Spark, Kafka, etc.\n  -  Relational SQL and NoSQL databases, including Oracle ,SQL server and Cassandra. \n  -  Data pipeline and workflow management tools:  Airflow.\n  -  Cloud services: Amazon EC2, EMR, S3, or Google Bigquery.\n  -  Object-oriented/object function scripting languages: Python, Java, Scala.\n  -  Oracle eco-system: ODI, OBIEE, Oracle Golden gate, Data modeler.\nAVENUE JSC\nSEP 2014 - OCT 2016\nRole: Leader of KPI and Data warehouse team\n\u2022 Work with external team to design and build the Data warehouse system with ETL tool\n( OGG,ODI).\n\u2022 Run workshop with Customer to design and build FDS,FRS Document ( Computation\nlevel, Visualization chart, Fomula..)\n\u2022 Analyze and specify the technical and functional data requirements of Customer\nPHAM DUC HUY\nData analysis Specialist\n\uf073Feb 05, 1991\n\uf007 Male\n\uf095 +65 81153212\n\uf199 duchuydn11@gmail.com\n\uf041 Singapore\n\uf129 Skype:duchuy_ueh                      \n  Whatapps +65 81153212\nOBJECTIVE\nI found out capable of analyzing\nmyself after experienced in some\nprojects and I recognize that it's a\nreally big objective in my career.\nWorking in the environment that big\ndata are served analyzing and\nforecasting ;such as banking,\ntelecom system is challenge.Now I\nam reaching to big project that my\nskills are luminescent to become\ndata scientist.\nSKILLS\nProficiency in the use of BI\nTool(IBM Cognos, OBIEE, Tablue)\nAnalytics language: R\nAbility in using ETL Tool ( OGG,\nADFv1,v2, Pentaho)\nBigdata technologies (Hive query,\nSpark,Hadoop HDFS, Azure blob\nstorage)\nAWS Cloud ( S3 storage, Hue, EMR\ncluster)\nINTERESTS\nFootbal\nMusic\nGo backpacking\nReading\nFPT SOFTWARE HCM\n2012 - AUG 2014\n\u2022 Discuss with Consultants to analysis the GAPs between CMMS system vs KPI\nspecification and clarify Customer's requirement.\n\u2022 Work with Develop team to build KPI reports on BI Cognos reporting Tool.\n\u2022 Coordinate with Partner Oracle to extract and transform data; serve building data\nwarehouse\n\u2022 Training and coaching member to catch up on Project\nExperience:\n - Business: CMMS Maximo\n - Relational database: Oracle database, SQL server\n - Data platform: Oracle data guard, Oracle golden date\n - BI solution: IBM Cognos version 10, version11.\n - Database management: Oracle EM.\n - BI OLAP cube: Cognos framework.\nRole: Business Analyst\n\u2022 Run workshop with Customer to get requirement and design FDS document.\n\u2022 Analyze customers\u2019 requirement and match their process to DMS system\nAchievements and skills gained: \n\u2022 Work with develop Team to design Data flow Diagram\n\u2022 Involve in test and release product process (design test case, test scenario..)\nAREAS OF EXPERTISE\n2017 - NOW\nTOPICAL PROJECT IN MOMO\n2016 - 2017\nMOMO: DATA PLATFORM (DATA WAREHOUSE)\n2016 - 2017\nCUSTOMER: BIENDONG POC\n2015\n\uf0c0 ACHIEVEMENTS\n  \u2022 Master all aspects of Oracle Business Intelligence Enterprise Edition (OBI EE)\ndevelopment & administration, including system installation, creating Analyses and\nDashboards, Scorecards and Key Performance Indicators, Prompts and Variables,\nintegrating BI Content with MS Office, working with BI Content in Smart View, building\nRepositories, modeling Time Series data, security, administering the Presentation\nServices Catalog, using Oracle BI Delivers, Oracle BI Publisher\n  \u2022 Master some aspects of Oracle Business Intelligence Application (BI Apps)\ndevelopment, including setting up BIACM, performing, administering and maintaining\nFunctional Configuration, customizing the Oracle Business Analytics Warehouse,\nconfiguring Data Linear, integrating security for Oracle BI Apps with EBS\u2026\n  \u2022 Good knowledge of Data Warehouse Architecture, Implementation and\nAdministration, Oracle Database Architecture\n  \u2022 Good knowledge of OLAP, Data Mining, Data Mart, Partitioning, Indexing, Parallelism,\nMaterialized Views, ETL\nUser properties model for analytics.\nRecommendation system.\nResponsible for designing, building and development.\n\u2022 Build the synchronization model via the Satellite successfully.\nWe coordinate Oracle consultant to setup and config two-way synchronization model\nbetween off-shore and on-shore using Oracle Golden Gate  11g\nBINH SON REFINERY:\n2015\n\u2022 Implement KPI phase 1 for Maintenance department\nWe work with Consultant and BSR Core Team to define and build KPIs group to\nevaluate resource utilization. In this project,I work as Team Leader to discuss\nConsultant and Customer to clarify GAP analysis and tranform to Dev team. I am also\nresponsible for developing Framwork model and design on reporting tool. (Using IBM\nCognos reporting ver 10.2)\nBINH SON REFINERY:\n2016\n\u2022 Data warehouse standard Project\nWe cooperate with Oracle at Viet Nam to design and setup Data warehouse model. We\nwork with Oracle Tools serve Customer's data center system standardize  Star schema\nmodel. (Using Oracle Data Integrator, Oracle Golden Gate version 12c)\n\uf0f6 CERTIFICATIONS\n\u2022 IBM Certified Administrator Cognos 10 BI\n\u2022 IBM Certified Deployment Professional Maximo Asset\nManagement V7.5\n\u2022 IBM Certified Deployment Professional Tivoli Process\nAutomation Engine V7.5\n\u2022 Microsoft Certification 761- Querying Data with Transact-\nSQL\n\u2022 Microsoft Certification 762- Developing SQL Database\n\uf091\nHONORS & AWARDS\nThe third of ACM programing contest in University since 2012\n2013-2014\n\uf040\nADDITIONAL INFORMATION\nExperience in webservice on cloud with big data technology is advantage that is\nsuitable for your requirement. \nWith numbers of customer is rising up while we have to handle large of user's event\ndata that become big problem that all fin-tech company facing. Momo resolved that\nproblem with a ELT-framework that allows transform each block data to cloud service\nand take advantage of distribution technology to process and calculate.\n\uf097 REFERENCES\nMr Alvin Ng, Just Analytics company\nFounder and Managing Consultant\nPhone: (+65) 9682 2210 \nEmail: Alvin.Ng@justanalytics.com\nMr.D\u01b0\u01a1ng Qu\u1ef3nh\nLine Manager in FPT Software\nPhone: 0906 777 041\nEmail: QuynhD2@fsoft.com.vn\n\u00a9 topcv.vn", "educations": [{"id": 4783, "gpa": "7.6", "major": "Qu\u1ea3n l\u00fd th\u00f4ng tin", "school": "UNIVERSITY ECONOMIC OF HCM", "diploma": "Bachelors", "end_time": "2013-04-01T00:00:00Z", "conf_score": 0.8413267261986577, "start_time": "2009-08-01T00:00:00Z", "picklist_major": "Administrative/Clerical", "major_categories": "B\u00e1o ch\u00ed v\u00e0 th\u00f4ng tin", "major_categories_detail": "Th\u00f4ng tin \u2013 Th\u01b0 vi\u1ec7n"}], "experiences": [{"id": 16026, "detail": "I\u2019m a consultant for Business Intelligence and Azure data lake storage over 4 years of experience in the Information Technology industry in administering the data of the organization professionally. I have demonstrated ability to effectively communicate with local customers and conduct complete project life cycles, from initial planning and needs determination to final testing and deployment of Azure storage as back-end, front-end of which is implemented by using Power BI and Rstudio. I continue to be involved with every phase of the life cycle development, including business requirement analysis, designing, organizing and maintaining the data collected from diverse sources and building the large and medium Data Warehouse and Business Intelligence projects, some are using Oracle BI Apps to implementand HDFS. I also have hands-on experience in designing, developing and implementing in Data pipeline for Data streaming as Azure stream analytics. I\u2019m detail oriented and commited to delivering superior quality work. I\u2019m seeking a challenging position as a Data Scientists with an organization where high responsibility, fast learning, good communication with clients, effective problem solving skills, leadership and organizational skills would be needed.", "company": "JUST ANALYTICS", "end_time": "2023-04-13T00:00:00Z", "industry": "Other", "position": "Technical Consultant", "conf_score": 0.9542271074073599, "start_time": "2018-04-01T00:00:00Z"}, {"id": 16027, "detail": "As the part of the best fin-tech company in Vietnam, my responsibility is to aggregate data from many sources to build-up a decision support system to give the warning or strategy decision for board of management. Beside, we also design process to transform data in non-SQL structure of customers (videos, audio, record, image, emotion..) to meaningful data that user properties is core support analyzing and answer user's behaviour and their character.\nExperience: - Big data tools: Hadoop, Spark, Kafka, etc.\n- Relational SQL and NoSQL databases, including Oracle ,SQL server and Cassandra. - Data pipeline and workflow management tools: Airflow. - Cloud services: Amazon EC2, EMR, S3, or Google Bigquery. - Object-oriented/object function scripting languages: Python, Java, Scala. - Oracle eco-system: ODI, OBIEE, Oracle Golden gate, Data modeler.", "company": "MSERVICE - MOMO", "end_time": "2018-04-30T00:00:00Z", "industry": "Other", "position": "Business intelligence Manager", "conf_score": 0.9542271074073599, "start_time": "2016-01-01T00:00:00Z"}, {"id": 16028, "detail": "\u2022 Work with external team to design and build the Data warehouse system with ETL tool\n( OGG,ODI). \u2022 Run workshop with Customer to design and build FDS,FRS Document ( Computation level, Visualization chart, Fomula..) \u2022 Analyze and specify the technical and functional data requirements of Customer \u2022 Discuss with Consultants to analysis the GAPs between CMMS system vs KPI specification and clarify Customer's requirement.\n\u2022 Work with Develop team to build KPI reports on BI Cognos reporting Tool. \u2022 Coordinate with Partner Oracle to extract and transform data; serve building data warehouse\n\u2022 Training and coaching member to catch up on Project Experience: - Business: CMMS Maximo - Relational database: Oracle database, SQL server\n- Data platform: Oracle data guard, Oracle golden date\n- BI solution: IBM Cognos version 10, version11.\n- Database management: Oracle EM. - BI OLAP cube: Cognos framework.", "company": "AVENUE JSC", "end_time": "2016-10-31T00:00:00Z", "industry": "Other", "position": "Leader of KPI and Data warehouse team", "conf_score": 0.9542271074073599, "start_time": "2014-09-01T00:00:00Z"}, {"id": 16029, "detail": "\u2022 Run workshop with Customer to get requirement and design FDS document.\n\u2022 Analyze customers\u2019 requirement and match their process to DMS system\nAchievements and skills gained:\n\u2022 Work with develop Team to design Data flow Diagram \u2022 Involve in test and release product process (design test case, test scenario..)", "company": "FPT SOFTWARE HCM", "end_time": "2014-08-31T00:00:00Z", "industry": "High Technology", "position": "Business Analyst", "conf_score": 0.9283402044765778, "start_time": "2012-01-01T00:00:00Z"}], "address": null}